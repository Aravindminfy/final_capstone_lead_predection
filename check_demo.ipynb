{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda1782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9240 entries, 0 to 9239\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                         Non-Null Count  Dtype  \n",
      "---  ------                                         --------------  -----  \n",
      " 0   Prospect ID                                    9240 non-null   object \n",
      " 1   Lead Number                                    9240 non-null   int64  \n",
      " 2   Lead Origin                                    9240 non-null   object \n",
      " 3   Lead Source                                    9204 non-null   object \n",
      " 4   Do Not Email                                   9240 non-null   object \n",
      " 5   Do Not Call                                    9240 non-null   object \n",
      " 6   Converted                                      9240 non-null   int64  \n",
      " 7   TotalVisits                                    9103 non-null   float64\n",
      " 8   Total Time Spent on Website                    9240 non-null   int64  \n",
      " 9   Page Views Per Visit                           9103 non-null   float64\n",
      " 10  Last Activity                                  9137 non-null   object \n",
      " 11  Country                                        6779 non-null   object \n",
      " 12  Specialization                                 7802 non-null   object \n",
      " 13  How did you hear about X Education             7033 non-null   object \n",
      " 14  What is your current occupation                6550 non-null   object \n",
      " 15  What matters most to you in choosing a course  6531 non-null   object \n",
      " 16  Search                                         9240 non-null   object \n",
      " 17  Magazine                                       9240 non-null   object \n",
      " 18  Newspaper Article                              9240 non-null   object \n",
      " 19  X Education Forums                             9240 non-null   object \n",
      " 20  Newspaper                                      9240 non-null   object \n",
      " 21  Digital Advertisement                          9240 non-null   object \n",
      " 22  Through Recommendations                        9240 non-null   object \n",
      " 23  Receive More Updates About Our Courses         9240 non-null   object \n",
      " 24  Tags                                           5887 non-null   object \n",
      " 25  Lead Quality                                   4473 non-null   object \n",
      " 26  Update me on Supply Chain Content              9240 non-null   object \n",
      " 27  Get updates on DM Content                      9240 non-null   object \n",
      " 28  Lead Profile                                   6531 non-null   object \n",
      " 29  City                                           7820 non-null   object \n",
      " 30  Asymmetrique Activity Index                    5022 non-null   object \n",
      " 31  Asymmetrique Profile Index                     5022 non-null   object \n",
      " 32  Asymmetrique Activity Score                    5022 non-null   float64\n",
      " 33  Asymmetrique Profile Score                     5022 non-null   float64\n",
      " 34  I agree to pay the amount through cheque       9240 non-null   object \n",
      " 35  A free copy of Mastering The Interview         9240 non-null   object \n",
      " 36  Last Notable Activity                          9240 non-null   object \n",
      "dtypes: float64(4), int64(3), object(30)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'C:\\Users\\Minfy.DESKTOP-3E50D5N\\Desktop\\final_capstone\\raw_data\\Lead Scoring.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ColumnMapping' from 'evidently' (c:\\Users\\Minfy.DESKTOP-3E50D5N\\Desktop\\final_capstone\\venv\\Lib\\site-packages\\evidently\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mevidently\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnMapping\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mevidently\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Report\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mevidently\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetric_suite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MetricSuite\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'ColumnMapping' from 'evidently' (c:\\Users\\Minfy.DESKTOP-3E50D5N\\Desktop\\final_capstone\\venv\\Lib\\site-packages\\evidently\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from evidently import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metric_suite import MetricSuite\n",
    "from evidently.metrics import (\n",
    "    DataDriftTable, \n",
    "    DatasetDriftMetric, \n",
    "    ColumnDriftMetric,\n",
    "    DatasetSummaryMetric,\n",
    "    ColumnSummaryMetric\n",
    ")\n",
    "from evidently.test_suite import TestSuite\n",
    "from evidently.tests import (\n",
    "    TestNumberOfDriftedColumns,\n",
    "    TestColumnDrift,\n",
    "    TestShareOfDriftedColumns\n",
    ")\n",
    "from typing import Dict, List, Optional, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EvidentlyDataDriftDetector:\n",
    "    \"\"\"\n",
    "    A comprehensive data drift detection system using Evidently AI library.\n",
    "    Compares distributions between reference (main) and current datasets to identify data drift.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 drift_threshold: float = 0.5,\n",
    "                 confidence_level: float = 0.95,\n",
    "                 categorical_threshold: float = 0.2):\n",
    "        \"\"\"\n",
    "        Initialize the Evidently Data Drift Detector.\n",
    "        \n",
    "        Args:\n",
    "            drift_threshold (float): Threshold for detecting dataset-level drift (0-1)\n",
    "            confidence_level (float): Confidence level for statistical tests\n",
    "            categorical_threshold (float): Threshold for categorical drift detection\n",
    "        \"\"\"\n",
    "        self.drift_threshold = drift_threshold\n",
    "        self.confidence_level = confidence_level\n",
    "        self.categorical_threshold = categorical_threshold\n",
    "        self.column_mapping = None\n",
    "        self.drift_report = None\n",
    "        self.test_suite = None\n",
    "        \n",
    "    def setup_column_mapping(self, \n",
    "                           numerical_features: Optional[List[str]] = None,\n",
    "                           categorical_features: Optional[List[str]] = None,\n",
    "                           target_column: Optional[str] = None,\n",
    "                           prediction_column: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        Set up column mapping for Evidently to understand data types.\n",
    "        \n",
    "        Args:\n",
    "            numerical_features (List[str], optional): List of numerical column names\n",
    "            categorical_features (List[str], optional): List of categorical column names\n",
    "            target_column (str, optional): Name of target column\n",
    "            prediction_column (str, optional): Name of prediction column\n",
    "        \"\"\"\n",
    "        self.column_mapping = ColumnMapping(\n",
    "            numerical_features=numerical_features,\n",
    "            categorical_features=categorical_features,\n",
    "            target=target_column,\n",
    "            prediction=prediction_column\n",
    "        )\n",
    "        print(\"Column mapping configured successfully\")\n",
    "    \n",
    "    def detect_drift(self, \n",
    "                    reference_data: pd.DataFrame, \n",
    "                    current_data: pd.DataFrame,\n",
    "                    save_report: bool = True,\n",
    "                    report_path: str = \"drift_report.html\") -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Main method to detect data drift between reference and current datasets.\n",
    "        \n",
    "        Args:\n",
    "            reference_data (pd.DataFrame): Reference/baseline dataset\n",
    "            current_data (pd.DataFrame): Current dataset to compare against reference\n",
    "            save_report (bool): Whether to save HTML report\n",
    "            report_path (str): Path to save the HTML report\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing comprehensive drift detection results\n",
    "        \"\"\"\n",
    "        # Validate input data\n",
    "        self._validate_data(reference_data, current_data)\n",
    "        \n",
    "        # Auto-detect column types if not provided\n",
    "        if self.column_mapping is None:\n",
    "            self._auto_detect_column_types(reference_data)\n",
    "        \n",
    "        # Generate drift report\n",
    "        self._generate_drift_report(reference_data, current_data)\n",
    "        \n",
    "        # Run drift tests\n",
    "        self._run_drift_tests(reference_data, current_data)\n",
    "        \n",
    "        # Extract and return results\n",
    "        results = self._extract_drift_results()\n",
    "        \n",
    "        # Save HTML report if requested\n",
    "        if save_report:\n",
    "            self.save_html_report(report_path)\n",
    "            print(f\"Drift report saved to: {report_path}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _validate_data(self, reference_data: pd.DataFrame, current_data: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Validate input datasets for basic requirements.\n",
    "        \n",
    "        Args:\n",
    "            reference_data (pd.DataFrame): Reference dataset\n",
    "            current_data (pd.DataFrame): Current dataset\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If datasets don't meet basic requirements\n",
    "        \"\"\"\n",
    "        if reference_data.empty or current_data.empty:\n",
    "            raise ValueError(\"Both datasets must contain data\")\n",
    "        \n",
    "        common_columns = set(reference_data.columns) & set(current_data.columns)\n",
    "        if len(common_columns) == 0:\n",
    "            raise ValueError(\"Datasets must have at least one common column\")\n",
    "        \n",
    "        print(f\"✓ Validation passed\")\n",
    "        print(f\"  - Common columns: {len(common_columns)}\")\n",
    "        print(f\"  - Reference data shape: {reference_data.shape}\")\n",
    "        print(f\"  - Current data shape: {current_data.shape}\")\n",
    "    \n",
    "    def _auto_detect_column_types(self, data: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Automatically detect column types for Evidently mapping.\n",
    "        \n",
    "        Args:\n",
    "            data (pd.DataFrame): Dataset to analyze for column types\n",
    "        \"\"\"\n",
    "        numerical_features = []\n",
    "        categorical_features = []\n",
    "        \n",
    "        for column in data.columns:\n",
    "            if pd.api.types.is_numeric_dtype(data[column]):\n",
    "                numerical_features.append(column)\n",
    "            else:\n",
    "                categorical_features.append(column)\n",
    "        \n",
    "        self.column_mapping = ColumnMapping(\n",
    "            numerical_features=numerical_features if numerical_features else None,\n",
    "            categorical_features=categorical_features if categorical_features else None\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ Auto-detected column types:\")\n",
    "        print(f\"  - Numerical: {len(numerical_features)} columns\")\n",
    "        print(f\"  - Categorical: {len(categorical_features)} columns\")\n",
    "    \n",
    "    def _generate_drift_report(self, reference_data: pd.DataFrame, current_data: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Generate comprehensive drift report using Evidently metrics.\n",
    "        \n",
    "        Args:\n",
    "            reference_data (pd.DataFrame): Reference dataset\n",
    "            current_data (pd.DataFrame): Current dataset\n",
    "        \"\"\"\n",
    "        # Create drift report with multiple metrics\n",
    "        self.drift_report = Report(metrics=[\n",
    "            DatasetDriftMetric(),\n",
    "            DataDriftTable(),\n",
    "            DatasetSummaryMetric(),\n",
    "        ])\n",
    "        \n",
    "        # Add individual column drift metrics for each column\n",
    "        for column in reference_data.columns:\n",
    "            if column in current_data.columns:\n",
    "                self.drift_report.metrics.append(ColumnDriftMetric(column_name=column))\n",
    "                self.drift_report.metrics.append(ColumnSummaryMetric(column_name=column))\n",
    "        \n",
    "        # Run the report\n",
    "        self.drift_report.run(\n",
    "            reference_data=reference_data,\n",
    "            current_data=current_data,\n",
    "            column_mapping=self.column_mapping\n",
    "        )\n",
    "        \n",
    "        print(\"✓ Drift report generated successfully\")\n",
    "    \n",
    "    def _run_drift_tests(self, reference_data: pd.DataFrame, current_data: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Run drift tests to get pass/fail results.\n",
    "        \n",
    "        Args:\n",
    "            reference_data (pd.DataFrame): Reference dataset\n",
    "            current_data (pd.DataFrame): Current dataset\n",
    "        \"\"\"\n",
    "        # Create test suite with drift tests\n",
    "        tests = [\n",
    "            TestNumberOfDriftedColumns(),\n",
    "            TestShareOfDriftedColumns(lt=self.drift_threshold),\n",
    "        ]\n",
    "        \n",
    "        # Add individual column drift tests\n",
    "        for column in reference_data.columns:\n",
    "            if column in current_data.columns:\n",
    "                tests.append(TestColumnDrift(column_name=column))\n",
    "        \n",
    "        self.test_suite = TestSuite(tests=tests)\n",
    "        \n",
    "        # Run the tests\n",
    "        self.test_suite.run(\n",
    "            reference_data=reference_data,\n",
    "            current_data=current_data,\n",
    "            column_mapping=self.column_mapping\n",
    "        )\n",
    "        \n",
    "        print(\"✓ Drift tests completed\")\n",
    "    \n",
    "    def _extract_drift_results(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extract drift detection results from Evidently report and tests.\n",
    "        \n",
    "        Returns:\n",
    "            Dict containing structured drift results\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'dataset_drift': {},\n",
    "            'column_drift': {},\n",
    "            'summary': {},\n",
    "            'test_results': {}\n",
    "        }\n",
    "        \n",
    "        # Extract dataset-level drift\n",
    "        dataset_drift_metric = self.drift_report.get_metric(\"DatasetDriftMetric\")\n",
    "        if dataset_drift_metric:\n",
    "            results['dataset_drift'] = {\n",
    "                'drift_detected': dataset_drift_metric.result.drift_detected,\n",
    "                'drift_score': dataset_drift_metric.result.drift_score,\n",
    "                'number_of_drifted_columns': dataset_drift_metric.result.number_of_drifted_columns,\n",
    "                'total_columns': len(dataset_drift_metric.result.drift_by_columns)\n",
    "            }\n",
    "        \n",
    "        # Extract column-level drift\n",
    "        data_drift_table = self.drift_report.get_metric(\"DataDriftTable\")\n",
    "        if data_drift_table:\n",
    "            for column_name, drift_info in data_drift_table.result.drift_by_columns.items():\n",
    "                results['column_drift'][column_name] = {\n",
    "                    'drift_detected': drift_info.drift_detected,\n",
    "                    'drift_score': drift_info.drift_score,\n",
    "                    'stattest_name': drift_info.stattest_name,\n",
    "                    'threshold': drift_info.threshold,\n",
    "                    'p_value': getattr(drift_info, 'p_value', None)\n",
    "                }\n",
    "        \n",
    "        # Extract dataset summary\n",
    "        dataset_summary = self.drift_report.get_metric(\"DatasetSummaryMetric\")\n",
    "        if dataset_summary:\n",
    "            results['summary'] = {\n",
    "                'reference_data_rows': dataset_summary.result.reference.number_of_rows,\n",
    "                'current_data_rows': dataset_summary.result.current.number_of_rows,\n",
    "                'reference_data_columns': dataset_summary.result.reference.number_of_columns,\n",
    "                'current_data_columns': dataset_summary.result.current.number_of_columns,\n",
    "            }\n",
    "        \n",
    "        # Extract test results\n",
    "        if self.test_suite:\n",
    "            test_results = self.test_suite.as_dict()\n",
    "            results['test_results'] = {\n",
    "                'tests_passed': sum(1 for test in test_results['tests'] if test['status'] == 'SUCCESS'),\n",
    "                'tests_failed': sum(1 for test in test_results['tests'] if test['status'] == 'FAIL'),\n",
    "                'total_tests': len(test_results['tests']),\n",
    "                'detailed_results': test_results['tests']\n",
    "            }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_html_report(self, file_path: str = \"drift_report.html\") -> None:\n",
    "        \"\"\"\n",
    "        Save the drift report as an HTML file.\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): Path where to save the HTML report\n",
    "        \"\"\"\n",
    "        if self.drift_report is None:\n",
    "            raise ValueError(\"No drift report available. Run detect_drift() first.\")\n",
    "        \n",
    "        self.drift_report.save_html(file_path)\n",
    "        print(f\"✓ HTML report saved to: {file_path}\")\n",
    "    \n",
    "    def print_drift_summary(self, results: Dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Print a formatted summary of drift detection results.\n",
    "        \n",
    "        Args:\n",
    "            results (Dict): Results from detect_drift method\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"                 DRIFT DETECTION SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Dataset-level summary\n",
    "        if 'dataset_drift' in results:\n",
    "            dataset_drift = results['dataset_drift']\n",
    "            print(f\"\\n📊 DATASET-LEVEL DRIFT:\")\n",
    "            print(f\"  • Drift Detected: {'🚨 YES' if dataset_drift.get('drift_detected', False) else '✅ NO'}\")\n",
    "            print(f\"  • Drift Score: {dataset_drift.get('drift_score', 'N/A'):.4f}\")\n",
    "            print(f\"  • Drifted Columns: {dataset_drift.get('number_of_drifted_columns', 0)}/{dataset_drift.get('total_columns', 0)}\")\n",
    "        \n",
    "        # Column-level summary\n",
    "        if 'column_drift' in results:\n",
    "            print(f\"\\n📋 COLUMN-LEVEL DRIFT:\")\n",
    "            drifted_columns = []\n",
    "            stable_columns = []\n",
    "            \n",
    "            for column, drift_info in results['column_drift'].items():\n",
    "                if drift_info.get('drift_detected', False):\n",
    "                    drifted_columns.append(column)\n",
    "                else:\n",
    "                    stable_columns.append(column)\n",
    "            \n",
    "            print(f\"  • Drifted Columns ({len(drifted_columns)}): {', '.join(drifted_columns) if drifted_columns else 'None'}\")\n",
    "            print(f\"  • Stable Columns ({len(stable_columns)}): {', '.join(stable_columns) if stable_columns else 'None'}\")\n",
    "        \n",
    "        # Test results summary\n",
    "        if 'test_results' in results:\n",
    "            test_results = results['test_results']\n",
    "            print(f\"\\n🧪 TEST RESULTS:\")\n",
    "            print(f\"  • Tests Passed: {test_results.get('tests_passed', 0)}\")\n",
    "            print(f\"  • Tests Failed: {test_results.get('tests_failed', 0)}\")\n",
    "            print(f\"  • Total Tests: {test_results.get('total_tests', 0)}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "\n",
    "# Example usage and data loading section\n",
    "def load_sample_data():\n",
    "    \"\"\"\n",
    "    Generate sample datasets for demonstration.\n",
    "    Replace this with your actual data loading logic.\n",
    "    \"\"\"\n",
    "    print(\"\\n📁 SAMPLE DATA GENERATION\")\n",
    "    print(\"Replace this section with your actual data loading code\")\n",
    "    \n",
    "    # Generate reference dataset\n",
    "    np.random.seed(42)\n",
    "    reference_data = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0, 1, 1000),\n",
    "        'feature2': np.random.normal(5, 2, 1000),\n",
    "        'feature3': np.random.choice(['A', 'B', 'C'], 1000),\n",
    "        'feature4': np.random.exponential(2, 1000),\n",
    "        'target': np.random.choice([0, 1], 1000)\n",
    "    })\n",
    "    \n",
    "    # Generate current dataset with some drift\n",
    "    np.random.seed(123)\n",
    "    current_data = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0.5, 1.2, 800),  # Slight drift in mean and std\n",
    "        'feature2': np.random.normal(5, 2, 800),      # No drift\n",
    "        'feature3': np.random.choice(['A', 'B', 'C', 'D'], 800),  # New category\n",
    "        'feature4': np.random.exponential(1.5, 800),  # Drift in distribution\n",
    "        'target': np.random.choice([0, 1], 800)\n",
    "    })\n",
    "    \n",
    "    return reference_data, current_data\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function demonstrating the data drift detection system.\n",
    "    \"\"\"\n",
    "    print(\"🚀 STARTING DATA DRIFT DETECTION\")\n",
    "    \n",
    "    # ==========================================\n",
    "    # STEP 1: LOAD YOUR DATA HERE\n",
    "    # ==========================================\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STEP 1: DATA LOADING\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # TODO: Replace with your actual data loading\n",
    "    reference_data, current_data = load_sample_data()\n",
    "    \n",
    "    # Example of loading from files:\n",
    "    # reference_data = pd.read_csv('path/to/your/reference_data.csv')\n",
    "    # current_data = pd.read_csv('path/to/your/current_data.csv')\n",
    "    \n",
    "    print(f\"✓ Reference data loaded: {reference_data.shape}\")\n",
    "    print(f\"✓ Current data loaded: {current_data.shape}\")\n",
    "    \n",
    "    # ==========================================\n",
    "    # STEP 2: INITIALIZE DRIFT DETECTOR\n",
    "    # ==========================================\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STEP 2: INITIALIZING DRIFT DETECTOR\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Initialize the detector\n",
    "    detector = EvidentlyDataDriftDetector(\n",
    "        drift_threshold=0.5,  # Adjust based on your needs\n",
    "        confidence_level=0.95,\n",
    "        categorical_threshold=0.2\n",
    "    )\n",
    "    \n",
    "    # Optional: Set up column mapping if you want to specify column types\n",
    "    # detector.setup_column_mapping(\n",
    "    #     numerical_features=['feature1', 'feature2', 'feature4'],\n",
    "    #     categorical_features=['feature3'],\n",
    "    #     target_column='target'\n",
    "    # )\n",
    "    \n",
    "    # ==========================================\n",
    "    # STEP 3: DETECT DRIFT\n",
    "    # ==========================================\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STEP 3: DETECTING DRIFT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Run drift detection\n",
    "    results = detector.detect_drift(\n",
    "        reference_data=reference_data,\n",
    "        current_data=current_data,\n",
    "        save_report=True,\n",
    "        report_path=\"data_drift_report.html\"\n",
    "    )\n",
    "    \n",
    "    # ==========================================\n",
    "    # STEP 4: DISPLAY RESULTS\n",
    "    # ==========================================\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STEP 4: RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Print summary\n",
    "    detector.print_drift_summary(results)\n",
    "    \n",
    "    # Detailed results are available in the results dictionary\n",
    "    print(f\"\\n📄 Detailed results available in 'results' dictionary\")\n",
    "    print(f\"📊 Interactive HTML report saved as 'data_drift_report.html'\")\n",
    "    \n",
    "    return results, detector\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the drift detection system\n",
    "    results, detector = main()\n",
    "    \n",
    "    # Access specific results\n",
    "    print(\"\\n🔍 ACCESSING SPECIFIC RESULTS:\")\n",
    "    print(f\"Dataset drift detected: {results['dataset_drift'].get('drift_detected', 'N/A')}\")\n",
    "    print(f\"Number of drifted columns: {results['dataset_drift'].get('number_of_drifted_columns', 'N/A')}\")\n",
    "    \n",
    "    # You can also access individual column results\n",
    "    for column_name, column_drift in results['column_drift'].items():\n",
    "        if column_drift.get('drift_detected', False):\n",
    "            print(f\"Column '{column_name}' has drift (score: {column_drift.get('drift_score', 'N/A'):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
